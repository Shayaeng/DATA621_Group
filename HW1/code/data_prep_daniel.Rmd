---
title: "R Notebook"
output: html_notebook
---


```{r}
library(readr)
library(dplyr)
library(mice)
library(caret)
library(DescTools)
```

Sources Referenced:
- https://www.r-bloggers.com/2015/10/imputing-missing-data-with-r-mice-package/
- https://www.gerkovink.com/miceVignettes/


Steps:

- 5 Number Summary + Outlier Detection
- Deal with Outliers:
  - keep if a part of the data
  - if not apart of data population, remove
  - if error, try to fix (0 values and outliers)
  - Winsorize
- Transform
- Impute


https://cran.r-project.org/mirrors.html
```{r Load Data}
test <- read_csv("..\\data\\moneyball-evaluation-data.csv")
train <- read_csv("..\\data\\moneyball-training-data.csv")
```

```{r}
summary(train)
```

```{r Outliers}
boxplot(train)$out
text(colnames(train), srt = 45, pos = 1, xpd = TRUE)


for (col_name in names(train)) {
  
  boxplot(train[[col_name]], main = col_name)
  
}
```


Missing completely at random (MCAR) when the missingness mechanism is completely independent of the estimate of our parameter(s) of interest. Deletion will yield unbiased results.


Missing at random (MAR) when the missingness mechanism is conditionally independent of the estimate of our parameter(s) of interest. In short, the data with complete cases are biased.


Missing not at random (MNAR) when the missingness mechanism is associated with the estimate of our parameter(s) of interest

```{r}
percentMiss <- function(x){sum(is.na(x))/length(x)*100} # Creates percentage of missing values

variable_pMiss <- apply(train,2,percentMiss) # 2 = runs on columns
sample_pMiss <- apply(train,1,percentMiss) # 1 = runs on rows
```

```{r}
variable_pMiss
sum(sample_pMiss > 50)
```
|   We can see that most variables have low percentage miss rates. Two variables TEAM_BATTING_HBP and TEAM_BASERUN_CS have 91.6% and 33.9% missing rates which leads to a recommendation to remove at least TEAM_BATTING_HBP from the dataset. Should TEAM_BASERUN_CS be removed for having more than 25% of observations missing its value?


```{r Check Rows for Miss Data}

#Filters for instances where the entire row is NA
train <- train %>% 
  filter(if_any(everything(), ~ !is.na(.))) #keep rows that have atleast one value that is not NA

#if_any : https://www.tidyverse.org/blog/2021/02/dplyr-1-0-4-if-any/
#         https://dplyr.tidyverse.org/reference/across.html

```

```{r Check Cols for Miss Data}

#Filtering for instances where the entire column is NA

not_all_na <- function(x) any(!is.na(x)) 
# Create a function since where() only works with functions
# !is.na(x) returns a vector of T/F if it is not an NA value
# any() checks to see if any values in the vector are TRUE

train_cleaned <- train %>% select(where(not_all_na)) # Selects only columns that are not completely NA

```

```{r Drop TB_HBP and Rename}

train_cleaned <- train_cleaned %>% select (-TEAM_BATTING_HBP, -INDEX)

colnames(train_cleaned) <- c("Wins","Bat_H","Bat_2B","Bat_3B","Bat_HR","Bat_BB", "Bat_SO","Base_SB","Base_CS","Pitch_H","Pitch_HR","Pitch_BB","Pitch_SO","Field_E","Field_DP")

train_cleaned <- as.data.frame(train_cleaned)
```

# Dropping Outliers Technique

```{r}

calc_outliers <- function(column) { # Calculates the quantiles of the column
  Q1 <- quantile(column, 0.25, na.rm = TRUE)
  Q3 <- quantile(column, 0.75, na.rm = TRUE)
  
  # Calculates IQR
  IQR_val <- Q3 - Q1
  
  # Calculates the Outlier benchmark
  lower_limit <- Q1 - 1.5 * IQR_val
  upper_limit <- Q3 + 1.5 * IQR_val
  
  # Store Limits
  data.frame(lower_limit = lower_limit, upper_limit = upper_limit)
}

# Apply calculate_outlier_limits function to each column
limits <- lapply(train_cleaned, calc_outliers)

# Convert list to dataframe
limits <- do.call(rbind, limits)

```
```{r Filtering Based on Limits}

train_outs_drop <- train_cleaned

nrow(train_outs_drop)

train_outs_drop <- train_outs_drop %>%
  filter(Bat_H >1152 | Bat_H < 1769 | is.na(Bat_H))

train_outs_drop <- train_outs_drop %>%
  filter(Bat_2B > 111 | Bat_2B < 371 | is.na(Bat_2B))

train_outs_drop <- train_outs_drop %>% # Negative values are ignored
  filter(Bat_3B < 130 | is.na(Bat_3B)) # drops a good bit

train_outs_drop <- train_outs_drop %>%
  filter(Bat_HR < 304 | is.na(Bat_HR)) #none

train_outs_drop <- train_outs_drop %>%
  filter(Bat_BB > 257 | Bat_BB < 773 | is.na(Bat_BB)) #none

train_outs_drop <- train_outs_drop %>%
  filter(Bat_SO < 1503 | is.na(Bat_SO)) #drops  a good bit

train_outs_drop <- train_outs_drop %>%
  filter(Base_SB < 291 | is.na(Base_SB)) #drops a good bit

train_outs_drop <- train_outs_drop %>%
  filter(Base_CS > 2 | Base_CS < 98 | is.na(Base_CS))

train_outs_drop <- train_outs_drop %>%
  filter(Pitch_H > 1023 | Pitch_H < 2078 | is.na(Pitch_H) )

train_outs_drop <- train_outs_drop %>%
  filter(Pitch_HR < 300 | is.na(Pitch_HR))
nrow(train_outs_drop)

train_outs_drop <- train_outs_drop %>%
  filter(Pitch_BB > 274 | Pitch_BB < 813 | is.na(Pitch_BB))
nrow(train_outs_drop)

train_outs_drop <- train_outs_drop %>%
  filter(Pitch_SO > 84 | Pitch_SO < 1498 | is.na(Pitch_SO))
nrow(train_outs_drop)

train_outs_drop <- train_outs_drop %>%
  filter(Field_E < 432 | is.na(Field_E))
nrow(train_outs_drop)

train_outs_drop <- train_outs_drop %>%
  filter(Field_DP > 81 | Field_DP < 214 | is.na(Field_DP))
nrow(train_outs_drop)


```

```{r Histograms of Out Drop Data}
for (col_name in colnames(train_outs_drop)) {
  hist(train_outs_drop[[col_name]], main = col_name, xlab = col_name)
}

```


# Winsorized Data 

```{r Winsorize the Data}

Wins <- train_cleaned$Wins
train_winsor <- train_cleaned[-1] # removing wins to avoid winsorizing them

for (col in colnames(train_winsor[-1])) {
  train_winsor[[col]] <- Winsorize(train_winsor[[col]], na.rm = TRUE)
}

train_winsor <- data.frame(Wins,train_winsor)
```

## Checking Outliers and Distribution after Winsor

```{r Histograms of Untampered Data}
for (col_name in colnames(train_cleaned)) {
  hist(train_cleaned[[col_name]], main = col_name, xlab = col_name)
}

```


```{r}
for (col_name in colnames(train_winsor)) {
  hist(train_winsor[[col_name]], main = col_name, xlab = col_name)
}
```

```{r Boxplots after Winsor}
# Checks impacts of Winsorizing the dataframe
# Pitch_H and Field_E still have many outliers

boxplot(train_winsor)$out
text(colnames(train_winsor), srt = 45, pos = 1, xpd = TRUE)


for (col_name in names(train_winsor)) {
  
  boxplot(train_winsor[[col_name]], main = col_name)
  
}
```

```{r}
summary(train_winsor)
```

```{r}
summary(train_cleaned)
```
## Checking 0 Values

Since only one row has a 0 value, and it is in the Wins column. It will be left in the dataset as it seems a possible value.

```{r}

colnames(train_winsor)

rows_with_zero <- which(apply(train_winsor == 0, 1, any)) # apply will create a vector of T/F that determines if row has 0 in it
# which()

train_winsor[1,]

train_winsor[rows_with_zero,]

```


```{r Check 0s for Dataset of Dropped Outliers 0s}

colnames(train_outs_drop)

rows_with_zero <- which(apply(train_outs_drop == 0, 1, any)) # apply will create a vector of T/F that determines if row has 0 in it
# which()

train_winsor[1,]

train_outs_drop[rows_with_zero,]
```

```{r Check 0s for Dataset of Basic Cleaned Data}

rows_with_zero <- which(apply(train_cleaned == 0, 1, any)) # apply will create a vector of T/F that determines if row has 0 in it
# which()


train_cleaned[rows_with_zero,]

```
|    28 rows contain a 0 for one of its values. These 0 values are extremely unlikely and will be replaced with NAs. After replacing with NAs, we will see if any samples have more than 50% of its variables missing for removal.

```{r train_0 NA Count}
# Replace 0 values with NA's in rows
train_0 <- apply(train_cleaned, 2, function(col) replace(col, col == 0, NA))

# Convert the matrix back to a dataframe
train_0 <- as.data.frame(train_0)


train_0 <- train_0 %>% filter(rowSums(is.na(train_0))<7)

```


# Transform (BoxCox)


## BoxCox Transformation of Minimal Clean Data
```{r}
preProcValues_0 <- preProcess(train_0, method = "BoxCox") #-1 to remove win

trainBC_0 <- predict(preProcValues_0, train_0)

preProcValues_0$bc

trainBC_0
```


## BoxCox Transformation of Winsorized Data

```{r Winsor Transform}
preProcValues_winsor <- preProcess(train_winsor, method = "BoxCox")

trainBC_winsor <- predict(preProcValues_winsor, train_winsor)

preProcValues_winsor

trainBC_winsor
# Winsor Transformed: Bat_H, Bat_2B, Bat_3B, Bat_HR, Bat_BB, Bat_SO, Base_SB, Base_CS, Pitch_H, Pitch_HR, Pitch_BB, Pitch_SO, Field_E, Field_DP

# Non-Winsor cols_trans <- c("Bat_H","Bat_2B","Pitch_H","Field_E","Field_DP")
```


## Normality Before/After Transformation Winsorized
```{r}
for (col_name in colnames(trainBC_winsor[-1])) { #-1 removes the Wins columns
  hist(trainBC_winsor[[col_name]], main = col_name, xlab = col_name)
}
```



# Transformation of non-winsorized data

```{r Winsor Transform}
preProcValues <- preProcess(train_cleaned, method = "BoxCox")

trainBC <- predict(preProcValues, train_cleaned)

preProcValues

trainBC

cols_trans <- c("Bat_H","Bat_2B","Pitch_H","Field_E","Field_DP")
```


## Normality Before/After for Non-Winsorized
```{r Before Trans}
for (col_name in cols_trans) {
  hist(train_cleaned[[col_name]], main = col_name, xlab = col_name)
}
```




|    For non-winsorized data, It looks like if outliers can be removed or dealt with, only Pitch_H and Field_E would be needed. For winsorized data, every column was transformed, implying a decrease in normality.

```{r Miss Pattern}

pattern <- md.pattern(train_cleaned, rotate.names = TRUE)

pattern <- as.data.frame(pattern)

pattern
```

|    Batting_HBP is missing for almost all observations and should be removed. There were no samples that had at least 50% of the variables missing, leading to the conclusion of keeping all observations. Only a maximum of 3 features are missing at a time. 3 features out of 14 is less than 50% of the feature count for a sample, so no observations need to be replaced.



|    Imputation will use the MICE package and using the predictive mean modeling method to generate predictions

#norm.predict (imputes based on the "best value" determined by linear reg)
#mice.impute.norm.boot (imputes by log reg with bootstrap aggregation, best for )
#norm.nob (imputes without accounting for parameter uncertainty, Bat_SO looks bad)
#norm (univariate missing data by Bayesian linear reg - Pitch_SO and Field_DP look ok)
#mpmm (imputes multivariate incomplete data that has relationships like polynomials)
#cart (imputes based on regression trees - Bat_SO matches great)

Before changing variables used in prediction methods. The best methods that match are:
Bat_SO - CART
Norm - Pitch_SO and Field_DP
Norm.nob - for any other than Bat_SO
Mean - for Base_SB and Base_CS, Pitch_SO? Field_DP


CART was used for Bat_SO and Pitch_SO as their distributions matched well. Base SB, Base_CS, and Field_DP worked well with mean.


# Imputing Winsorized Data
```{r}
#methods_vec_WinsorBC <- c("","","","","","","rf","pmm","pmm","","","","cart","","pmm") #Winsorized data methods

train_imputed_WinsorBC <- mice(trainBC_winsor,method = "pmm", m=5, maxit = 50, seed = 500, print = F)

densityplot(train_imputed_WinsorBC)
```

# Imputing Non-Winsorized Data

```{r MICE Impute, echo = FALSE}
train_imputed <- mice(trainBC, print=F) #instantiating to get access to method matrix




train_imputed_BC <- mice(trainBC,method = "pmm", m=5, maxit = 50, seed = 500, print = F)
```

```{r}
#summary(train_imputed_BC)
```

```{r}
#train_imputed$imp$Bat_SO
```

```{r}
densityplot(train_imputed_BC)
```

# 

```{r}
#stripplot(train_imputed, Bat_SO+Base_SB+Base_CS+Pitch_SO+Field_DP~.imp, pch=20, cex=2)
```


## Adding Ratios

1. TEAM_BATTING_H_TEAM_PITCHING_H_RATIO
2. TEAM_BATTING_HR_TEAM_PITCHING_HR_RATIO
3. TEAM_BATTING_BB_TEAM_PITCHING_BB_RATIO
4. TEAM_BATTING_SO_TEAM_PITCHING_SO_RATIO 

```{r}
imputes_1 <- complete(train_imputed, 1)
imputes_2 <- complete(train_imputed, 2)
imputes_3 <- complete(train_imputed, 3)
imputes_4 <- complete(train_imputed, 4)
imputes_5 <- complete(train_imputed, 5)

imputed_ratios <- imputes_1 %>%
  mutate(Ratio_Bat_H_Pitch_H = Bat_H / Pitch_H,
         Ratio_Bat_HR_Pitch_HR = Bat_HR / Pitch_HR,
         Ratio_Bat_BB_Pitch_BB = Bat_BB / Pitch_BB,
         Ratio_Bat_SO_Pitch_SO = Bat_SO / Pitch_SO
         )

```



## 

```{r Write Imputed Data}
write_csv(imputed_ratios, "imputed_ratios.csv")

```

Example Code I left to find out why my xyplot() wasn't showing red observations:

```{r}
imp <- mice(boys, maxit = 1)

# xyplot: scatterplot by imputation number
# observe the erroneous outlying imputed values
# (caused by imputing hgt from bmi)
xyplot(imp, hgt ~ age, pch = c(1, 20), cex = c(1, 1.5))

# same, but label with missingness of wgt (four cases)
xyplot(imp, hgt ~ age | .imp, na.group = wgt, pch = c(1, 20), cex = c(1, 1.5))
```

